{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 05:45:20.898757: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-13 05:45:20.925187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 05:45:21.296846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tb_data(root_dir, sort_by=None, exp_name=''):\n",
    "    \"\"\"Convert local TensorBoard data into Pandas DataFrame.\n",
    "    \n",
    "    Function takes the root directory path and recursively parses\n",
    "    all events data.    \n",
    "    If the `sort_by` value is provided then it will use that column\n",
    "    to sort values; typically `wall_time` or `step`.\n",
    "    \n",
    "    *Note* that the whole data is converted into a DataFrame.\n",
    "    Depending on the data size this might take a while. If it takes\n",
    "    too long then narrow it to some sub-directories.\n",
    "    \n",
    "    Paramters:\n",
    "        root_dir: (str) path to root dir with tensorboard data.\n",
    "        sort_by: (optional str) column name to sort by.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame with [wall_time, name, step, value] columns.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def convert_tfevent(filepath):\n",
    "        return pd.DataFrame([\n",
    "            parse_tfevent(e) for e in summary_iterator(filepath) if len(e.summary.value)\n",
    "        ])\n",
    "\n",
    "    def parse_tfevent(tfevent):\n",
    "        return dict(\n",
    "            wall_time=tfevent.wall_time,\n",
    "            name=tfevent.summary.value[0].tag,\n",
    "            step=tfevent.step,\n",
    "            value=float(tf.make_ndarray(tfevent.summary.value[0].tensor)),\n",
    "        )\n",
    "    \n",
    "    columns_order = ['wall_time', 'name', 'step', 'value']\n",
    "    \n",
    "    out = []\n",
    "    for (root, _, filenames) in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if \"events.out.tfevents\" not in filename:\n",
    "                continue\n",
    "            file_full_path = os.path.join(root, filename)\n",
    "            out.append(convert_tfevent(file_full_path))\n",
    "\n",
    "    # Concatenate (and sort) all partial individual dataframes\n",
    "    all_df = pd.concat(out)[columns_order]\n",
    "    if sort_by is not None:\n",
    "        all_df = all_df.sort_values(sort_by)\n",
    "\n",
    "    all_df.name = all_df.name.apply(lambda name: exp_name + \"/\" + name)\n",
    "        \n",
    "    return all_df.reset_index(drop=True)\n",
    "\n",
    "def plot_category(df, category_name, interpolate=True, interval_window=100, compute_ewm=True, ewm_alpha=0.25):\n",
    "    category_df = df[df.name.str.endswith(category_name)]\n",
    "    category_df.index.name = 'index'\n",
    "    \n",
    "    assert category_df.shape[0] > 0, \"Invalid category '%s'\" % category_name\n",
    "\n",
    "    if interpolate:\n",
    "        index_name = 'step'\n",
    "        interpolated_df = pd.DataFrame(columns=['value', 'name'])\n",
    "        interpolated_df.index.name = index_name\n",
    "\n",
    "        # get names of folders\n",
    "        names = category_df.name.unique()\n",
    "\n",
    "        # Re sample rewards by fix intervals for comparison between different runs\n",
    "        for name in names:\n",
    "            intervals = np.arange(0, int(category_df['step'].iloc[-1])+1, interval_window)\n",
    "            name_df = category_df.loc[category_df.name == name]\n",
    "            interval_df = name_df.groupby(pd.cut(name_df['step'], intervals, labels=intervals[1:]))['value'].mean().interpolate().fillna(value=0.0).to_frame()\n",
    "            interval_df['name'] = name\n",
    "            interpolated_df = pd.concat([interpolated_df, interval_df])\n",
    "    else:\n",
    "        index_name = 'index'\n",
    "        interpolated_df = category_df\n",
    "\n",
    "    plot_data = None\n",
    "    if compute_ewm:\n",
    "        # Compute exponential moving average (smoothing)\n",
    "        groups = interpolated_df.groupby('name')\n",
    "        ewm_df = groups.value.ewm(alpha=ewm_alpha).mean().reset_index().set_index(index_name).rename(columns={\"value\":\"ewm\"})\n",
    "        postprocessing_df = pd.merge(interpolated_df, ewm_df, how='left', left_on=[index_name, 'name'], right_on=[index_name, 'name'])\n",
    "        postprocessing_df.ewm = postprocessing_df[\"ewm\"]\n",
    "        plot_data = 'ewm'\n",
    "        plot_df = postprocessing_df\n",
    "    else:\n",
    "        plot_data = 'value'\n",
    "        plot_df = interpolated_df\n",
    "\n",
    "    # Plot by aggregaring runs with common name\n",
    "    indicator = interpolated_df.name.apply(lambda name: name.split(\"__\")[0]).to_numpy()\n",
    "    sns.lineplot(data=plot_df, x=\"step\", y=plot_data, hue=indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/o2ac-ur/clean_results/SAC_slicing_3d__S.069357/', '/root/o2ac-ur/clean_results/SAC_slicing_3d2__-S.402498/', '/root/o2ac-ur/clean_results/SAC_slicing_3d__S.880481/']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"/root/trufus/clean_results/\"\n",
    "root_directory = \"/root/o2ac-ur/clean_results/\"\n",
    "\n",
    "directory_list = glob.glob(root_directory + \"*/\")\n",
    "print(directory_list)\n",
    "\n",
    "csv_list = glob.glob(root_directory + \"*.csv\")\n",
    "print(csv_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAC_slicing_3d__S.069357\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/summary/summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "SAC_slicing_3d2__-S.402498\n",
      "SAC_slicing_3d__S.880481\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "for dir in directory_list:\n",
    "    exp_name = dir.split(\"/\")[-2]\n",
    "    print(exp_name)\n",
    "    all_data.append(convert_tb_data(dir, sort_by=\"step\", exp_name=exp_name))\n",
    "# for csv_file in csv_list:\n",
    "#     all_data.append(pd.read_csv(csv_file))\n",
    "\n",
    "df = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'ewm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_category(df, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_episode_length\u001b[39;49m\u001b[39m\"\u001b[39;49m, ewm_alpha\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, interval_window\u001b[39m=\u001b[39;49m\u001b[39m250\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mEpisode length\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m, in \u001b[0;36mplot_category\u001b[0;34m(df, category_name, interpolate, interval_window, compute_ewm, ewm_alpha)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m compute_ewm:\n\u001b[1;32m     81\u001b[0m     \u001b[39m# Compute exponential moving average (smoothing)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     groups \u001b[39m=\u001b[39m interpolated_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m     ewm_df \u001b[39m=\u001b[39m groups\u001b[39m.\u001b[39;49mvalue\u001b[39m.\u001b[39;49mewm(alpha\u001b[39m=\u001b[39mewm_alpha)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mset_index(index_name)\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mewm\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m     84\u001b[0m     postprocessing_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(interpolated_df, ewm_df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, left_on\u001b[39m=\u001b[39m[index_name, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], right_on\u001b[39m=\u001b[39m[index_name, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     85\u001b[0m     postprocessing_df\u001b[39m.\u001b[39mewm \u001b[39m=\u001b[39m postprocessing_df[\u001b[39m\"\u001b[39m\u001b[39mewm\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/groupby.py:703\u001b[0m, in \u001b[0;36m_GroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[1;32m    701\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[attr]\n\u001b[0;32m--> 703\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    704\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'ewm'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "print(pandas.__version__)\n",
    "plot_category(df, \"training_episode_length\", ewm_alpha=0.2, interval_window=250)\n",
    "plt.title(\"\")\n",
    "plt.ylabel(\"Episode length\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.grid()\n",
    "plt.ylim(0, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df, \"training_return\", ewm_alpha=0.2, interval_window=250)\n",
    "plt.title(\"\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.grid()\n",
    "# plt.ylim(0, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df, \"success_rate\", interpolate=False, compute_ewm=True, ewm_alpha=0.5, interval_window=5000)\n",
    "plt.title(\"\")\n",
    "plt.ylabel(\"Training return\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.grid()\n",
    "# plt.ylim(-80, -10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
