ur3e_gym: #namespace
    # General Agent parameters
    env_id: "UR3eSlicingEnv-v1"
    controller_type: "cartesian_compliance"
    namespace: "b_bot"

    reset_robot: True
    real_robot: False
    test_mode: False

    relative_to_ee: False
    robot_control_dt: 0.002
    agent_control_dt: 0.05
    reset_time: 2.0
    # actions parameters 
    n_actions: 12
    action_type: "admittance"
    
    object_name: "target_block_tmp"
    object_centric: False
    ee_centric: False

    steps_per_episode: 300
    
    actor_class: "wave"
    ft_hist: True
    wrench_hist_size: 6
    duration_as_obs: False
    last_action_as_obs: True
    normalize_velocity: True

    rand_seed: 3215   
    rand_interval: 1

    # Curriculum parameters
    initial_curriculum_level: 0.05
    curriculum_level_step: 0.05
    cl_upgrade_level: 0.9
    cl_downgrade_level: 0.2
    cumulative_episode_num: 0 # for linear curriculum
    curriculum_learning: False
    progressive_cl: False
    reward_based_on_cl: False

    # Domain Randomization Parameters
    object_friction: 1
    object_stiffness: 400
    max_stiffness_range: [200, 500]
    max_damping_range: [0, 1]
    max_kp_range: [4.0e+5, 1.0e+6]
    max_kd_range: [1, 2]

    ## Target object configuration
    randomize_object_properties: True
    normal_randomization: True
    basic_randomization: False
    # object_initial_pose: [-0.12, 0.0, 0.88, 1.5707, -1.5707, 3.1415] # cucumber
    object_initial_pose: [-0.12, 0.03, 0.89, 0, 0, 1.5707] # button
    object_workspace: [[-0.05, 0.05], [-0.05, 0.05], [0.08, 0.02], [-20, 20], [-20, 20], [-60, 60]]
    max_object_workspace: [0.08, 0.08, 0.08, 20, 20, 60]
    min_object_workspace: [0.02, 0.02, 0.02, 5, 5, 10]

    # initial conditions
    random_initial_pose: False
    # for each dimension define upper and lower bound from initial pose
    max_distance: [0.1, 0.1, 0.1, 0.785398, 0.785398, 1.5707]
    workspace: [[-0.1,0.1], [-0.1, 0.1], [0.0, 0.05], [20, -20], [20, -20], [20, -20]]
    # init_q: [1.3494, -1.5217, 1.8083, -1.8459, -1.564, 1.3481] # real slice 
    init_q: [1.3524, -1.5555, 1.7697, -1.7785, -1.5644, 1.3493] # sim button
    

    target_duration: 6
    target_pose_uncertain: False
    uncertainty_std: [0.001, 0.0]
    random_target_pose: False
    target_pose: [-0.02025, 0.51132, 0.19749, -0.00455, 0.70882, -0.00528, 0.70535]
    
    # Reward parameters
    tgt_pose_indices: [0,1,2,3,4,5]
    
    position_threshold: 0.005
    max_position_threshold: 0.01   # new 0.05
    orientation_threshold: 0.0349066
    max_orientation_threshold: 0.07

    reward_type: 'dense-distance-velocity-force'
    termination_on_negative_reward: True
    termination_reward_threshold: -500 # new -500

    cost:
        collision: -500.0
        done: 200
        step: -1.0  # new -1
    w_dist: 1.0
    w_force: 1.0
        
# Controller parameters
ur3e_force_control:
    max_force_torque: [30, 30.0, 30.0, 3, 3, 3]
    desired_force_torque: [0.0, 0.0, -10.0, 0.0, 0.0, 0.0]
