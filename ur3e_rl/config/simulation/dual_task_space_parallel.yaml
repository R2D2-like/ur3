ur3e_gym: #namespace
    # General Agent parameters
    env_id: "DualUR3eTaskSpaceFTEnv-v0"
    controller_type: "parallel_position_force" # or "admittance"
    driver: "gazebo" # or "robot" or "old_driver"
    ft_sensor: True
    relative_to_ee: False
    robot_control_dt: 0.002
    agent_control_dt: 0.05
    reset_time: 1.0

    steps_per_episode: 300
    
    ft_hist: True
    actor_class: "wave"

    rand_seed: 10   
    # initial conditions
    random_initial_pose: False
    rand_init_interval: 1
    # for each dimension define upper and lower bound from initial pose
    workspace: [[0.04,-0.04], [0.04, -0.04], [0.005, 0.02], [10, -10], [10, -10], [10, -10]]
    l_init_q: [2.5529, -1.2111, -1.4186, -0.546, 0.5781, -0.0237]
    r_init_q: [1.5388, -1.211, -1.4186, -0.546, 1.6476, -0.0237]

    target_pose_uncertain: False
    uncertainty_std: [0.001, 0.0]
    left_target_pos: [0.182, -0.25935, 0.44532, -0.01546, 0.71477, -0.69886, -0.02141]
    right_target_pos: [-0.25628, -0.19247, 0.493, -0.02357, 0.71887, -0.6947, 0.00793]
    extra_ee: [0, 0, 0.05, 0, 0, 0, 1]
    end_effector_points: [[0.,0.,0.]]
    
    # actions parameters 
    n_actions: 14
    
    # Reward parameters
    tgt_pose_indices: [0,1,2,3,4,5]
    distance_threshold: 5.0
    reward_type: 'zero'
    cost_positive: True
    cost:
        l1: 1.0
        l2: 10.0
        ws: [1.0,1.0,0.1]
        alpha: 0.00001
        goal: 100
        speed_violation: -1.0
        ik_violation: -1.0
        collision: -50.0
        
# Controller parameters
ur3e_force_control:
    n_actions: 14
    robot_control_dt: 0.002
    
    max_speed: [0.02,0.02,0.02,0.1,0.1,0.1] # per agent action
    action_scale: [1., 1., 1., 1., 1., 1.]

    max_force_torque: [40.0, 40.0, 40.0, 2, 2, 2]
    desired_force_torque: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
    
    # parallel control parameters
    pd_range_type: 'mult' # or 'sum'
    base_position_kp: [3.0, 3.0, 3.0, 2.0, 2.0, 2.0]
    kpd_range: 2
    base_force_kp: [5.0e-3, 5.0e-3, 5.0e-3, 2.5e-1, 2.5e-1, 2.5e-1]
    kpi_range: 2
    
    alpha: [0.5,0.5,0.5,0.5,0.5,0.5] # keep a degree of compliance
    alpha_base: 0.5
    alpha_range: 0.4