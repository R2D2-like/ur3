ur3e_gym: #namespace
    # Agent parameters
    env_id: "UR3ePegInHoleEnv-v0"
    controller_type: "parallel_position_force"
    driver: "gazebo"
    ft_sensor: True
    relative_to_ee: False
    robot_control_dt: 0.002
    agent_control_dt: 0.05
    reset_time: 1.0

    steps_per_episode: 300
    
    gazebo_models: True
    gazebo_model_stiffness: 9.0e+4
    gazebo_models_episode_num: 2000

    ft_hist: True
    actor_class: "wave"

    rand_seed: 10

    # initial conditions
    randomize_desired_force: False
    randomize_desired_force_scale: 10.0
    random_initial_pose: True
    rand_init_interval: 1
    target_pose_uncertain: False
    uncertainty_std: [0.003, 3.0]
    changable_goal: True
    goal_changer_interval: 2000
    # for each dimension define upper and lower bound from initial pose
    workspace: [[0.04,-0.04], [0.04, -0.04], [0.005, 0.02], [10, -10], [10, -10], [10, -10]]
    goals: [
        [-2.24462, -1.67999,  1.891  , -3.48903,  5.38531,  0.09558],
    ]
    target_pos: [-0.00312934, -0.37939538,  0.4540351 , -0.00235073, -0.6813838 ,  0.73190453, -0.00513233]
    extra_ee: [0, 0, 0.05, 0, 0, 0, 1]
    end_effector_points: [[0.,0.,0.]]
    
    # actions parameters 
    n_actions: 24 # 6 positions force + 2 kp parameters + 2 alphas
    
    # Reward parameters
    tgt_pose_indices: [0,1,2,3,4,5]
    distance_threshold: 1.0
    reward_type: 'force'
    cost_positive: True
    max_action: 24
    cost:
        l1: 1.0
        l2: 10.0
        ws: [0.0,1.0,0.0]
        alpha: 0.00001
        goal: 100
        step: 0.0
        speed_violation: -1.0
        ik_violation: -1.0
        collision: -50.0
        
# Controller parameters
ur3e_force_control:
    robot_control_dt: 0.002
    max_speed: [0.02,0.02,0.02,0.01,0.01,0.01]
    position_indices: [0,1,2,3,4,5]
    max_force_torque: [40.0, 40.0, 40.0, 2, 2, 2]
    desired_force_torque: [0.0, 0.0, 5.0, 0.0, 0.0, 0.0]
    action_scale: [1., 1., 1., 1., 1., 1.]
    n_actions: 24

    # Hybrid control parameters
    base_position_kp: 500
    position_pd_exp_base: [1.0e-2, 1.0e-2, 1.0e-2, 6.0e-2, 6.0e-2, 6.0e-2]
    kpd_range: 400
    base_force_kp: 500
    force_pd_exp_base: [1.0e-5, 1.0e-5, 1.0e-5, 5.0e-4, 5.0e-4, 5.0e-4]
    kpi_range: 400
    
    alpha: [0.7,0.7,0.7,0.7,0.7,0.7] # keep a degree of compliance
    alpha_base: 0.5
    alpha_range: 0.4