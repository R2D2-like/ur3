ur3e_gym: #namespace
    # General Agent parameters
    env_id: "UR3eForceControlEnv-v0"
    controller_type: "parallel_position_force" # or "admittance"

    ft_sensor: True
    relative_to_ee: False
    robot_control_dt: 0.002
    agent_control_dt: 0.05
    reset_time: 2.0

    steps_per_episode: 200
    
    ft_hist: False
    actor_class: "default"

    rand_seed: 10   
    rand_interval: 1
    target_duration: 5

    duration_as_obs: True
    
    # initial conditions
    random_initial_pose: False
    # for each dimension define upper and lower bound from initial pose
    workspace: [[0.10,-0.06], [0.05, -0.05], [0.05, -0.07], [45, -10], [10, -30], [45, -45]]
    init_q: [1.5086, -1.3787, 1.6721, -1.8872, -1.5656, -0.0419]

    target_duration: 3
    target_pose_uncertain: False
    uncertainty_std: [0.001, 0.0]
    random_target_pose: True
    target_pose: [-0.10717, 0.37138, 0.14324, 0.70785, 0.70628, -0.00664, 0.00863]
    
    # actions parameters 
    n_actions: 18
        
    position_threshold: 0.005
    orientation_threshold: 0.0174533 # 1 degree

    reward_type: 'dense-pdft'

    cost:
        collision: -100.0
        done: 100
        
# Controller parameters
ur3e_force_control:
    n_actions: 18
    robot_control_dt: 0.002
    
    max_speed: [0.02,0.02,0.02,0.1,0.1,0.1] # per agent action
    action_scale: [1., 1., 1., 1., 1., 1.]

    max_force_torque: [40.0, 40.0, 40.0, 2, 2, 2]
    desired_force_torque: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
    
    # parallel control parameters
    pd_range_type: 'mult' # or 'sum'
    base_position_kp: [4.0, 4.0, 4.0, 10.0, 10.0, 10.0]
    kpd_range: 2
    base_force_kp: [5.0e-3, 5.0e-3, 5.0e-3, 2.5e-1, 2.5e-1, 2.5e-1]
    kpi_range: 2
    
    alpha: [0.5,0.5,0.5,0.5,0.5,0.5] # keep a degree of compliance
    alpha_base: 0.5
    alpha_range: 0.49